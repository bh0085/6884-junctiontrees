{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size: smaller; color: #808080; text-align: center; display: block;\">MIT - 6.884 Computational Aspects of Therapeutics Design, Fall 2019</div>\n",
    "\n",
    "# Problem Set 1: Junction Tree Variational Autoencoder for Molecular Graph Generation \n",
    "In this problem set, you will experiment with neural network learning parameters to train the variational auto-encoder presented in [Junction Tree Variational Autoencoder for Molecular Graph Generation](https://arxiv.org/pdf/1802.04364.pdf). Using this trained VAE model, you will generate a random sample of valid chemical structures and visualize the structures using rdkit. Before starting this problem set, please read the paper, being sure that you understand it well enought to have an understanding of the technique which is illustrated in this diagram:\n",
    "![Figure 3](https://github.com/bh0085/6884-junctiontrees/blob/master/assets/ps1_fig3.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. INITIALIZATION\n",
    "\n",
    "This code and all of the code which follows is designed to be run in a Google Cloud Compute Datalab environment, with- or without GPU support. Instructions for setup are located in the README document at the PS1 github repo, [here](https://github.com/bh0085/6884-junctiontrees). We have included tips and notes related to many of the common challenges initializing a Datalab environment. Please let us know if you have any questions! \n",
    "\n",
    "Once you have followed the Datalab initialization steps detailed in Github, you should be running this notebook inside of a functional Datalab environmetn. We will need to add some dependencies to get things working. To complete Part 0, simply run the following code to intialize your datalab environment for small molecule design with Rdkit, PyTorch 0.4.1 and all necessary dependencies and imports.\n",
    "\n",
    "NOTE: **Want to run in your local environment?** This notebook should run in your local environment, however some dependencies of rdkit may require a package manager such as apt-get to install. If you're running in an ubuntu environment that should be fine. For users running in a mac environment, you will need to follow the rdkit instructions on [rdkit.org](https://www.rdkit.org) to get rdkit imports working. All users will need conda installed. The code in this notebook assumes a Datalab environment, but has notes where local users will probably have to make changes. \n",
    "\n",
    "NOTE: **Want to run on a GPU?** The ps1 README contains instructions for GPU & CPU setup. Running the GPU variant of this code may yield a 50% increase, but some of our students reported problems running `datalab beta create-gpu`. For those users, we have commented out the two places where the model uses CUDA. Let us know if you would like to debug GPU setup with us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Intialize datalab environment**  \n",
    "Run this code block to execute bash commands initializing your datalab envoironment for rdkit and pytorch which will be required to run this set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chown root:root /tmp\n",
    "!chmod 1777 /tmp\n",
    "!echo \"done fixing temp directory permissions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install system dependencies for rdkit to work\n",
    "# @LOCAL-USERS: you may not need to run this code or to run these commands in the terminal.\n",
    "# That's fine! Just make sure that your Rdkit imports work.\n",
    "# You can test this by running: from rdkit import Chem.Draw\n",
    "!apt-get update\n",
    "!apt-get install libfontconfig1 libxrender1 --yes\n",
    "!apt-get install libxext6 --yes\n",
    "!echo \"done installing dependencies\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install conda dependencies in bash\n",
    "# @LOCAL MACHINE USERS: Shell command support in Jupyter notebooks can be finicky. \n",
    "# You may find it more helpful to run these commands in the terminal.\n",
    "!conda install pytorch=0.4.1 --yes\n",
    "!conda install -c conda-forge rdkit --yes\n",
    "!conda install -c rdkit nox --yes\n",
    "!conda install -c rdkit cairo --yes\n",
    "!echo \"done installing conda packages\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialize imports and system path variables**  \n",
    "First, you will add to path the github repo which was downloaded below. \n",
    "\n",
    "NOTE: **@LOCAL MACHINE USERS**: This import is designed for the file structure of the google compute datalab environment, using an absolute path for the github repo cloned above. If you wish to run this code on your local machine, then you will need to change the path below to match the current working directory on your machine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the PS1 dependencies\n",
    "# if for some reason you need to re-run this code, rm -r the current github repo:\n",
    "# rm -r 6884-junctiontrees\n",
    "!git clone https://github.com/bh0085/6884-junctiontrees.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add PS1 dependencies to your python path\n",
    "import sys, os\n",
    "cwd = os.getcwd()\n",
    "sys.path.append(os.path.join(cwd,'6884-junctiontrees'))\n",
    "PS1_ROOT = os.path.join(cwd,\"6884-junctiontrees\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: **PYTHON 2**: The imports in this problem set will only work in a python 2 environment. This will be the default environment for Datalab users. If you are running this code on your home machine, you will need to swith to a python 2 evnironment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch, installed above\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import math, random, sys, os\n",
    "\n",
    "#import jtnn from the github repo \"./6884-junctiontrees\", downloaded above\n",
    "from jtnn import *\n",
    "\n",
    "#import rdkit, installed above\n",
    "import rdkit\n",
    "import rdkit.Chem as Chem\n",
    "from rdkit.Chem import Draw\n",
    "\n",
    "lg = rdkit.RDLogger.logger() \n",
    "lg.setLevel(rdkit.RDLogger.CRITICAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. PRETRAIN AUTOENCODER\n",
    "In the [junction trees paper](https://arxiv.org/pdf/1802.04364.pdf), the zinc dataset is analyzed to create a library of chemically valid molecular subgraphs, termed atomic clusters. These clusters have been pre-computed for you in `vocab.txt` and were chosen to have sufficient diversity to be joined in trees to cover the vast majority of molecules in the Zinc or MOSES datasets, located at `/data`.  \n",
    "<br/>\n",
    "\n",
    "In this problem set we will be working with the zinc dataset (`./6884-junctiontrees/data/zinc`). Problem 1 loads data from the zinc dataset to pretrain a model. As described in the junction tree paper, the pretraining phase will involve learning an autoencoder neural network similar to the final Variational Auto-encoder, but lacking the regularizing beta parameter. This pre-trained model will be used in the next step to initialize a full variational auto-encoder model.  \n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [PS1] @Students, the parameters below control the complexity of the neural network\n",
    "# which is will be used to encode / decode junction trees in this project in addition \n",
    "# to representing the latent space--ie: the lossy representation of the molecular backbone--\n",
    "# the choice of values will determine the speed of training and generalization (ie: test) \n",
    "# accuracy of the final outcome and influence the sampling results below. They will \n",
    "# also influence the speed of training significantly. In order to help you train larger sets,\n",
    "# we have also included a truncated version of the \"zinc\" dataset (see NOTE in the code below).\n",
    "# You can use this to experiment with larger hidden network sizes, but note that larger hidden\n",
    "# networks may have different training requirements that smaller ones!\n",
    "#\n",
    "# ... Read the paper and use your past experience to choose parameter values that will work here.\n",
    "#\n",
    "# Hint: Experiment with some parameter values based upon the paper, and if you have a \n",
    "# hard time getting results, you can try the values posted in the github repository associated \n",
    "# with the paper, https://arxiv.org/pdf/1802.04364.\n",
    "#\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "hidden_size= [...]\n",
    "latent_size= [...]\n",
    "depth=[...]\n",
    "### END CUSTOM CODE ###\n",
    "\n",
    "batch_size=40\n",
    "stereo=1\n",
    "\n",
    "DATA_PATH=\"../data/zinc\"\n",
    "OUT_DIR=\"../out/zinc\"\n",
    "\n",
    "# Calibration dataset paths\n",
    "# @STUDENTS: Uncomment this code to run on a reduced set of\n",
    "# training and testing data points. (see above)\n",
    "#\n",
    "# Training may take a long time to run.\n",
    "# To help you experiment with the data and ensure that your network is running,\n",
    "# you may want to test the code which follows on this limited dataset before\n",
    "# running on the full \"zinc\" dataset. Each of these contains 1/25 of the\n",
    "# molecules in training, testing, and validation sets.\n",
    "#\n",
    "# DATA_PATH=\"../data/zinc10k\"\n",
    "# OUT_DIR=\"../data/zinc10k\"\n",
    "#\n",
    "\n",
    "\n",
    "if not os.path.isdir(OUT_DIR): os.makedirs(OUT_DIR)\n",
    "\n",
    "VOCAB_PATH=os.path.join(DATA_PATH,\"vocab.txt\")\n",
    "TRAIN_PATH=os.path.join(DATA_PATH,\"train.txt\")\n",
    "TEST_PATH=os.path.join(DATA_PATH,\"test.txt\")\n",
    "\n",
    "vocab = [x.strip(\"\\r\\n \") for x in open(VOCAB_PATH)] \n",
    "vocab = Vocab(vocab)\n",
    "\n",
    "\n",
    "SAVE_PATH=os.path.join(OUT_DIR,\"pretraining\")\n",
    "if not os.path.isdir(SAVE_PATH): os.makedirs(SAVE_PATH)\n",
    "model = JTNNVAE(vocab, hidden_size, latent_size, depth)\n",
    "\n",
    "for param in model.parameters():\n",
    "    if param.dim() == 1:\n",
    "        nn.init.constant(param, 0)\n",
    "    else:\n",
    "        nn.init.xavier_normal(param)\n",
    "\n",
    "model = model#.cuda() #@GPU USERS: Uncomment .cuda() to run on this code on a GPU machine!\n",
    "print \"Model #Params: %dK\" % (sum([x.nelement() for x in model.parameters()]) / 1000,)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = lr_scheduler.ExponentialLR(optimizer, 0.9)\n",
    "scheduler.step()\n",
    "\n",
    "dataset = MoleculeDataset(TRAIN_PATH)\n",
    "\n",
    "MAX_EPOCH = 3\n",
    "PRINT_ITER = 20\n",
    "\n",
    "for epoch in xrange(MAX_EPOCH):\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4, collate_fn=lambda x:x, drop_last=True)\n",
    "\n",
    "    word_acc,topo_acc,assm_acc,steo_acc = 0,0,0,0\n",
    "\n",
    "    for it, batch in enumerate(dataloader):\n",
    "        for mol_tree in batch:\n",
    "            for node in mol_tree.nodes:\n",
    "                if node.label not in node.cands:\n",
    "                    node.cands.append(node.label)\n",
    "                    node.cand_mols.append(node.label_mol)\n",
    "\n",
    "        model.zero_grad()\n",
    "        loss, kl_div, wacc, tacc, sacc, dacc = model(batch, beta=0)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        word_acc += wacc\n",
    "        topo_acc += tacc\n",
    "        assm_acc += sacc\n",
    "        steo_acc += dacc\n",
    "\n",
    "        if (it + 1) % PRINT_ITER == 0:\n",
    "            word_acc = word_acc / PRINT_ITER * 100\n",
    "            topo_acc = topo_acc / PRINT_ITER * 100\n",
    "            assm_acc = assm_acc / PRINT_ITER * 100\n",
    "            steo_acc = steo_acc / PRINT_ITER * 100\n",
    "\n",
    "            print \"KL: %.1f, Word: %.2f, Topo: %.2f, Assm: %.2f, Steo: %.2f\" % (kl_div, word_acc, topo_acc, assm_acc, steo_acc)\n",
    "            word_acc,topo_acc,assm_acc,steo_acc = 0,0,0,0\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    scheduler.step()\n",
    "    print \"learning rate: %.6f\" % scheduler.get_lr()[0]\n",
    "    torch.save(model.state_dict(), SAVE_PATH + \"/model.iter-\" + str(epoch))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train Final VAE Model\n",
    "Students, in this section you will train the Variational Autoencoder starting from the pre-initialized model in Section 1. Code in this section is mostly fleshed out. All you need to do is please fill in neural network parameters. In order to complete this section, please fill in the neural network parameters`beta` and `lr`. We recommend reading the paper to find suggested values for these quantities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [PS1] 6.884 Students please experiment with values for regularization (beta) and learning rate (lr) based on the results of the paper. \n",
    "#\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "beta =[...]\n",
    "lr =[...]\n",
    "\n",
    "### YOUR CODE ENDS ###\n",
    "\n",
    "VAE_SAVE_PATH=os.path.join(OUT_DIR,\"vae_model\")\n",
    "MODEL_PATH=os.path.join(OUT_DIR,\"pretraining/model.iter-2\")\n",
    "if not os.path.isdir(VAE_SAVE_PATH): os.makedirs(VAE_SAVE_PATH)\n",
    "  \n",
    "stereo = True \n",
    "model = JTNNVAE(vocab, hidden_size, latent_size, depth, stereo=stereo)\n",
    "\n",
    "if MODEL_PATH is not None:\n",
    "    model.load_state_dict(torch.load(MODEL_PATH))\n",
    "else:\n",
    "    for param in model.parameters():\n",
    "        if param.dim() == 1:\n",
    "            nn.init.constant(param, 0)\n",
    "        else:\n",
    "            nn.init.xavier_normal(param)\n",
    "\n",
    "model = model#.cuda() #@GPU USERS: uncomment .cuda() to run on a GPU!\n",
    "print \"Model #Params: %dK\" % (sum([x.nelement() for x in model.parameters()]) / 1000,)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = lr_scheduler.ExponentialLR(optimizer, 0.9)\n",
    "scheduler.step()\n",
    "\n",
    "dataset = MoleculeDataset(TRAIN_PATH)\n",
    "\n",
    "MAX_EPOCH =7\n",
    "PRINT_ITER = 20\n",
    "for epoch in xrange(MAX_EPOCH):\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4, collate_fn=lambda x:x, drop_last=True)\n",
    "\n",
    "    word_acc,topo_acc,assm_acc,steo_acc = 0,0,0,0\n",
    "\n",
    "    for it, batch in enumerate(dataloader):\n",
    "        for mol_tree in batch:\n",
    "            for node in mol_tree.nodes:\n",
    "                if node.label not in node.cands:\n",
    "                    node.cands.append(node.label)\n",
    "                    node.cand_mols.append(node.label_mol)\n",
    "\n",
    "        try:\n",
    "            model.zero_grad()\n",
    "            loss, kl_div, wacc, tacc, sacc, dacc = model(batch, beta)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        except Exception as e:\n",
    "            print e\n",
    "            continue\n",
    "\n",
    "        word_acc += wacc\n",
    "        topo_acc += tacc\n",
    "        assm_acc += sacc\n",
    "        steo_acc += dacc\n",
    "\n",
    "        if (it + 1) % PRINT_ITER == 0:\n",
    "            word_acc = word_acc / PRINT_ITER * 100\n",
    "            topo_acc = topo_acc / PRINT_ITER * 100\n",
    "            assm_acc = assm_acc / PRINT_ITER * 100\n",
    "            steo_acc = steo_acc / PRINT_ITER * 100\n",
    "\n",
    "            print \"KL: %.1f, Word: %.2f, Topo: %.2f, Assm: %.2f, Steo: %.2f\" % (kl_div, word_acc, topo_acc, assm_acc, steo_acc)\n",
    "            word_acc,topo_acc,assm_acc,steo_acc = 0,0,0,0\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        if (it + 1) % 15000 == 0: #Fast annealing\n",
    "            scheduler.step()\n",
    "            print \"learning rate: %.6f\" % scheduler.get_lr()[0]\n",
    "\n",
    "        if (it + 1) % 1000 == 0: #Fast annealing\n",
    "            torch.save(model.state_dict(), VAE_SAVE_PATH + \"/model.iter-%d-%d\" % (epoch, it + 1))\n",
    "\n",
    "    scheduler.step()\n",
    "    print \"learning rate: %.6f\" % scheduler.get_lr()[0]\n",
    "    torch.save(model.state_dict(), VAE_SAVE_PATH + \"/model.iter-\" + str(epoch))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Sample new molecules\n",
    "In the junction trees paper, the Variational Autoencode is used to sample small molecules from the computed distribution. These molecules are converted to \"SMILES\" strings and tested for validity. In this part of the code, you will sample that distribution, outputting molecules in SMILES format which will be tested for validity below.\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAMPLE THE TRAINED VAE MODEL\n",
    "# [PS1] STUDENTS @Problem set 1, simply choose a sample number to print SMILES strings!\n",
    "### YOUR CODE HERE ###\n",
    "#\n",
    "nsample =100\n",
    "#\n",
    "### END CUSTOM CODE ###\n",
    "VAE_MODEL_PATH = os.path.join(OUT_DIR,\"vae_model/model.iter-4\")\n",
    "model = JTNNVAE(vocab, hidden_size, latent_size, depth, stereo=stereo)\n",
    "load_dict = torch.load(VAE_MODEL_PATH)\n",
    "missing = {k: v for k, v in model.state_dict().items() if k not in load_dict}\n",
    "load_dict.update(missing) \n",
    "model.load_state_dict(load_dict)\n",
    "model = model#.cuda()\n",
    "\n",
    "torch.manual_seed(0)\n",
    "samples = []\n",
    "for i in xrange(nsample):\n",
    "    s = model.sample_prior(prob_decode=False)\n",
    "    samples.append(s)\n",
    "    print(s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Visualize the output molecules\n",
    "This problem is more open-ended than previous parts. In the Junction Trees paper, the authors qualitatively evaluate the fidelity of molecular reconstructions by visualizing the small molecules which are sampled from the neighborhood of a chosen molecule. First to get a han As a consistency check on your results, utilize the Rdkit-based visualization tool from the Junction Trees paper to draw the randomly sampled molecules above.\n",
    "<br/><br/>\n",
    "Please fill in the code below to produce figures similar to the left side of Figure 6, below:\n",
    "\n",
    "**Figure 6**\n",
    "![Figure 6](https://github.com/bh0085/6884-junctiontrees/blob/master/assets/ps1_fig6.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your Code Here ###\n",
    "# [PS1] @Students, please use rdkit or another suitable molecular visualization \n",
    "# to draw one or more of the molecules sampled above.\n",
    "# \n",
    "# Hint: You may elect to use the methods of rdkit.Chem.Draw\n",
    "#\n",
    "##\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "\n",
    "### YOUR CODE ENDS ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: Helpful tips\n",
    "<br/><br/>\n",
    "**Cloud Datalab Docker Containers**\n",
    "Using Cloud Datalab, you may find it helpful to access the source code & system files of the underlying docker container. In this problem it should not be necessary to touch these parts of the system, but if you are interested in doing so, a useful guide can be found [here](https://cloud.google.com/datalab/docs/how-to/working-with-notebooks#using_git_from_the_command_line)\n",
    "\n",
    "<br/><br/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
